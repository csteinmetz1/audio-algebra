# AUTOGENERATED! DO NOT EDIT! File to edit: ../given-models.ipynb.

# %% ../given-models.ipynb 5
from __future__ import annotations  # for type hints LAION code samples
import numpy as np 
import torch
import torch.nn as nn
import torchaudio
from torchaudio import transforms as T
import pytorch_lightning as pl
import math
from tqdm import trange


# audio-diffusion imports
from copy import deepcopy
import pytorch_lightning as pl
from diffusion.pqmf import CachedPQMF as PQMF
from encoders.encoders import AttnResEncoder1D
from autoencoders.soundstream import SoundStreamXLEncoder
from dvae.residual_memcodes import ResidualMemcodes
from decoders.diffusion_decoder import DiffusionAttnUnet1D
from diffusion.model import ema_update
from einops import rearrange

from .DiffusionDVAE import DiffusionDVAE, sample

# %% auto 0
__all__ = ['GivenModelClass', 'SpectrogramAE', 'MagSpectrogramAE', 'MelSpectrogramAE', 'DVAEWrapper']

# %% ../given-models.ipynb 8
class GivenModelClass(nn.Module):
    "This provides an (optional) 'shorthand' structure for (some) given_models"
    def __init__(self,
        zero_pad=True,
        make_sizes_match=True,
        **kwargs,
        ):
        super().__init__()
        self.make_sizes_match, self.orig_shape, self.zero_pad  = make_sizes_match, None, zero_pad
    def setup(self):
        pass  
    def encode(self, waveform: torch.Tensor) -> torch.Tensor:
        return None
    def decode(self, waveform: torch.Tensor) -> torch.Tensor:
        return None    
    def forward(self, waveform: torch.Tensor)-> (torch.Tensor, torch.Tensor):
        reps = self.encode(waveform)
        recons = self.decode(reps)
        return (reps, recons)
    
    def match_sizes(self, recon) -> torch.Tensor:
        "match recon size to original waveform size, if possible"
        if self.make_sizes_match and (self.orig_shape is not None) and (recon.shape != self.orig_shape):
            if recon.shape[-1] > self.orig_shape[-1]:  # recon is longer
                recon = recon[:,:self.orig_shape[-1]]
            else: # recon is shorter
                recon2 = torch.zeros(self.orig_shape)  # slow but what are you gonna do
                recon2[:,:self.orig_shape[-1]] = recon
                recon = recon2 
            assert recon.shape == self.orig_shape, f"Did not succeed in making size match. recon.shape ({recon.shape}) != self.orig_shape ({self.orig_shape})"
        return recon       
    
    #--- couple extra routines probably only useful for fourier-based AE's but no harm done including them here
    def next_power_of_2(self, x:int) -> int:  
        return 1 if x == 0 else 2**(x - 1).bit_length()

    def zero_pad_po2(self, x:int) -> int:
        "useful for padding to nearest power of 2, useful for fourier-based transforms"
        new_shape = list(x.shape)
        new_shape[-1] = self.next_power_of_2(new_shape[-1])
        new_x = torch.zeros(new_shape)
        new_x[:,:x.shape[-1]] = x
        return new_x

# %% ../given-models.ipynb 10
class SpectrogramAE(GivenModelClass):
    "Raw (complex) spectrogram. See torchaudio.Spectrogram & InverseSpectrogram for kwarg info"
    def __init__(self,
        n_fft=1024,   
        hop_length=256,
        center=True,
        **kwargs,
    ):
        super().__init__()
        self.encoder = T.Spectrogram(power=None, n_fft=n_fft, hop_length=hop_length, center=center, **kwargs)
        self.decoder = T.InverseSpectrogram(    n_fft=n_fft, hop_length=hop_length, center=center, **kwargs)
        
    def encode(self, waveform: torch.Tensor) -> torch.Tensor:
        self.orig_shape = waveform.shape
        return self.encoder(self.zero_pad_po2(waveform)) if self.zero_pad else self.encoder(waveform)

    def decode(self, reps: torch.Tensor) -> torch.Tensor:
        return self.match_sizes( self.decoder(reps) )

# %% ../given-models.ipynb 14
class MagSpectrogramAE(GivenModelClass):
    "Magnitude spectrogram encoder, GriffinLim decoder"
    def __init__(self,
        n_fft=1024,   
        hop_length=256,
        center=True,
        **kwargs,
    ):
        super().__init__()
        self.encoder = T.Spectrogram(power=2, n_fft=n_fft, hop_length=hop_length, center=center, **kwargs)
        self.decoder = T.GriffinLim(          n_fft=n_fft, hop_length=hop_length, **kwargs)
        
    def encode(self, waveform: torch.Tensor) -> torch.Tensor:
        self.orig_shape = waveform.shape
        return self.encoder(self.zero_pad_po2(waveform)) if self.zero_pad else self.encoder(waveform)

    def decode(self, reps: torch.Tensor) -> torch.Tensor:
        return self.match_sizes( self.decoder(reps) )

# %% ../given-models.ipynb 16
class MelSpectrogramAE(GivenModelClass):
    "Mel spectrogram encoder, GriffinLim decoder"
    def __init__(self,
        sample_rate=48000,
        n_fft=1024,   
        hop_length=256,
        center=True,
        **kwargs,
    ):
        super().__init__()
        self.encoder = T.MelSpectrogram(sample_rate=sample_rate, n_fft=n_fft, hop_length=hop_length, center=center, **kwargs)
        inv_melscale_t = T.InverseMelScale(n_stft=n_fft // 2 + 1)  
        self.decoder = T.GriffinLim(n_fft=n_fft, hop_length=hop_length, **kwargs)
        
    def encode(self, waveform: torch.Tensor) -> torch.Tensor:
        self.orig_shape = waveform.shape
        return self.encoder(self.zero_pad_po2(waveform)) if self.zero_pad else self.encoder(waveform)

    def decode(self, melspec: torch.Tensor) -> torch.Tensor:
        spec = inv_melscale_t(melspec)
        return self.match_sizes( self.decoder(spec) )

# %% ../given-models.ipynb 20
class DVAEWrapper(GivenModelClass):
    "Wrapper for (hawley's fork of) Zach's DiffusionDVAE"
    def __init__(self, 
        args_dict = {'num_quantizers':0, 'sample_size': 65536, 'demo_steps':50, 'sample_rate':48000, 'latent_dim': 64, 'pqmf_bands':1, 'ema_decay':0.995, 'num_quantizers':0},
        device='cuda',
        debug=True,
        **kwargs,
    ):
        super().__init__()
        class DictObj:
            def __init__(self, in_dict:dict):
                for key, val in in_dict.items():
                    if isinstance(val, (list, tuple)):
                        setattr(self, key, [DictObj(x) if isinstance(x, dict) else x for x in val])
                    else:
                        setattr(self, key, DictObj(val) if isinstance(val, dict) else val)
        self.global_args = DictObj(args_dict)
        self.dvae_model = DiffusionDVAE(self.global_args)
        self.device = device
        self.noise = None 
        self.demo_steps = self.global_args.demo_steps
        self.demo_samples = self.global_args.sample_size 
        self.debug = debug
    
    def encode_it(self, demo_reals):
        module = self.dvae_model
        encoder_input = demo_reals
        print("demo_reals.shape = ",demo_reals.shape)

        if module.pqmf_bands > 1:
            encoder_input = module.pqmf(demo_reals)

        encoder_input = encoder_input.to(self.device)
        demo_reals = demo_reals.to(self.device)
        noise = torch.randn([demo_reals.shape[0], 2, self.demo_samples]).to(self.device)

        with torch.no_grad():
            embeddings = module.encoder_ema(encoder_input)
            if module.quantized:
                if debug: print("Hey, did you know you're quantized? ")
                #Rearrange for Memcodes
                embeddings = rearrange(embeddings, 'b d n -> b n d')
                embeddings, _= module.quantizer_ema(embeddings)
                embeddings = rearrange(embeddings, 'b n d -> b d n')
        
        embeddings = torch.tanh(embeddings)
        return embeddings, noise
        
    def encode(self, waveform: torch.Tensor) -> torch.Tensor:
        self.orig_shape = waveform.shape
        self.demo_samples = waveform.shape[-1]
        reps, self.noise = self.dvae_model.encode_it(waveform)
        return reps

    def decode(self, reps: torch.Tensor) -> torch.Tensor:
        print("reps.shape, self.noise.shape = ",reps.shape, self.noise.shape)
        fake_batches = sample(self.dvae_model.diffusion_ema, self.noise, self.demo_steps, 0, reps)
        recon = rearrange(fake_batches, 'b d n -> d (b n)') # Put the demos together
        return recon
    
    def setup(self, ckpt_file='/fsx/shawley/checkpoints/dvae_checkpoint.ckpt', device='cuda'):
        print(f"DVAE: attempting to load checkpoint {ckpt_file}")
        try:
            self.dvae_model = DiffusionDVAE.load_from_checkpoint(ckpt_file, global_args=self.global_args)
        except Exception as e:
            print(f"Sorry, exception = {e}. Going with random weights")
        self.dvae_model.encode_it = self.encode_it
        self.dvae_model.quantized = self.global_args.num_quantizers > 0 
        self.dvae_model.eval() # disable randomness, dropout, etc...
        self.dvae_model.to(self.device)
        freeze(self.dvae_model)  # freeze the weights for inference
